{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330af0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376e6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4711172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a72fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = dataset\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255  # x_trainv = x_trainv/255\n",
    "x_test /= 255\n",
    "\n",
    "num_classes=10\n",
    "y_trainc = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_testc = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5846c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 20,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"categorical_crossentropy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d402af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(28,28)))\n",
    "model.add(Flatten()) #Para aplanar las imagenes\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "#model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))) #Regularizacion L1L2\n",
    "#model.add(Dropout(0.2)) #Fraccion de enlaces a eliminar\n",
    "#model.add(Dense(200)) #Capa lineal , transformacion lineal sin funcion de activacion\n",
    "#model.add(Activation('tanh')) #Se puede agregar despues la funcion de activacion\n",
    "#model.add(Dense(400, activation='selu', kernel_regularizer=regularizers.L1(0.01) )) #Regularizacion L1\n",
    "#model.add(Dense(200, activation='elu', kernel_regularizer=regularizers.L2(l2=1e-4)) ) #Regularizacion L2\n",
    "#model.add(Dense(50,activation='exponential'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b52c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/02 17:16:51 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '019bb89460b2405faf3377577ecd298e', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  6/469 [..............................] - ETA: 4s - loss: 2.2254 - accuracy: 0.2487  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_train_batch_end` time: 0.0062s). Check your callbacks.\n",
      "469/469 [==============================] - 7s 12ms/step - loss: 0.4511 - accuracy: 0.8812 - val_loss: 0.2735 - val_accuracy: 0.9210\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.2490 - accuracy: 0.9279 - val_loss: 0.2147 - val_accuracy: 0.9381\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1947 - accuracy: 0.9436 - val_loss: 0.1735 - val_accuracy: 0.9481\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1562 - accuracy: 0.9543 - val_loss: 0.1457 - val_accuracy: 0.9565\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.1261 - accuracy: 0.9635 - val_loss: 0.1260 - val_accuracy: 0.9616\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.1046 - accuracy: 0.9704 - val_loss: 0.1067 - val_accuracy: 0.9685\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0872 - accuracy: 0.9757 - val_loss: 0.0966 - val_accuracy: 0.9693\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0739 - accuracy: 0.9790 - val_loss: 0.0861 - val_accuracy: 0.9722\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0619 - accuracy: 0.9824 - val_loss: 0.0815 - val_accuracy: 0.9747\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0527 - accuracy: 0.9852 - val_loss: 0.0780 - val_accuracy: 0.9766\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0451 - accuracy: 0.9873 - val_loss: 0.0728 - val_accuracy: 0.9766\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0381 - accuracy: 0.9896 - val_loss: 0.0685 - val_accuracy: 0.9784\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.0698 - val_accuracy: 0.9788\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0708 - val_accuracy: 0.9779\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0231 - accuracy: 0.9947 - val_loss: 0.0643 - val_accuracy: 0.9789\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0192 - accuracy: 0.9959 - val_loss: 0.0622 - val_accuracy: 0.9795\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0162 - accuracy: 0.9970 - val_loss: 0.0595 - val_accuracy: 0.9806\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.0623 - val_accuracy: 0.9811\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0628 - val_accuracy: 0.9803\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.0616 - val_accuracy: 0.9807\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\el_he\\AppData\\Local\\Temp\\tmp7ebn2af5\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\el_he\\AppData\\Local\\Temp\\tmp7ebn2af5\\model\\data\\model\\assets\n",
      "2023/10/02 17:19:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\el_he\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cd99bbcf70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=parameters['loss'],optimizer=parameters['optimizer'],metrics=['accuracy'])\n",
    "model.fit(x_train, y_trainc,\n",
    "                    batch_size=parameters['batch_size'],\n",
    "                    epochs=parameters[\"epochs\"],\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_testc)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe53c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5583fca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jinja2==3.0.3\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 0.0/133.6 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 30.7/133.6 kB ? eta -:--:--\n",
      "     -------------------------------- ----- 112.6/133.6 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 133.6/133.6 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\el_he\\anaconda3\\lib\\site-packages (from jinja2==3.0.3) (2.0.1)\n",
      "Installing collected packages: jinja2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.2\n",
      "    Uninstalling Jinja2-3.1.2:\n",
      "      Successfully uninstalled Jinja2-3.1.2\n",
      "Successfully installed jinja2-3.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jinja2==3.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7cb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
